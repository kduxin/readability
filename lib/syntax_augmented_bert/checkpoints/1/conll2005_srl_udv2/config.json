{
  "attention_probs_dropout_prob": 0.1,
  "crf": true,
  "finetuning_task": "conll2005wsj_srl",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label_map": {
    "B-A0": 1,
    "B-A1": 2,
    "B-A2": 3,
    "B-A3": 4,
    "B-A4": 5,
    "B-A5": 6,
    "B-AA": 7,
    "B-AM": 8,
    "B-AM-ADV": 9,
    "B-AM-CAU": 10,
    "B-AM-DIR": 11,
    "B-AM-DIS": 12,
    "B-AM-EXT": 13,
    "B-AM-LOC": 14,
    "B-AM-MNR": 15,
    "B-AM-MOD": 16,
    "B-AM-NEG": 17,
    "B-AM-PNC": 18,
    "B-AM-PRD": 19,
    "B-AM-REC": 20,
    "B-AM-TM": 21,
    "B-AM-TMP": 22,
    "B-C-A0": 23,
    "B-C-A1": 24,
    "B-C-A2": 25,
    "B-C-A3": 26,
    "B-C-A4": 27,
    "B-C-A5": 28,
    "B-C-AM-ADV": 29,
    "B-C-AM-CAU": 30,
    "B-C-AM-DIR": 31,
    "B-C-AM-DIS": 32,
    "B-C-AM-EXT": 33,
    "B-C-AM-LOC": 34,
    "B-C-AM-MNR": 35,
    "B-C-AM-NEG": 36,
    "B-C-AM-PNC": 37,
    "B-C-AM-TMP": 38,
    "B-C-V": 39,
    "B-R-A0": 40,
    "B-R-A1": 41,
    "B-R-A2": 42,
    "B-R-A3": 43,
    "B-R-A4": 44,
    "B-R-AA": 45,
    "B-R-AM-ADV": 46,
    "B-R-AM-CAU": 47,
    "B-R-AM-DIR": 48,
    "B-R-AM-EXT": 49,
    "B-R-AM-LOC": 50,
    "B-R-AM-MNR": 51,
    "B-R-AM-PNC": 52,
    "B-R-AM-TMP": 53,
    "B-V": 54,
    "I-A0": 55,
    "I-A1": 56,
    "I-A2": 57,
    "I-A3": 58,
    "I-A4": 59,
    "I-A5": 60,
    "I-AA": 61,
    "I-AM": 62,
    "I-AM-ADV": 63,
    "I-AM-CAU": 64,
    "I-AM-DIR": 65,
    "I-AM-DIS": 66,
    "I-AM-EXT": 67,
    "I-AM-LOC": 68,
    "I-AM-MNR": 69,
    "I-AM-MOD": 70,
    "I-AM-NEG": 71,
    "I-AM-PNC": 72,
    "I-AM-PRD": 73,
    "I-AM-REC": 74,
    "I-AM-TM": 75,
    "I-AM-TMP": 76,
    "I-C-A0": 77,
    "I-C-A1": 78,
    "I-C-A2": 79,
    "I-C-A3": 80,
    "I-C-A4": 81,
    "I-C-A5": 82,
    "I-C-AM-ADV": 83,
    "I-C-AM-CAU": 84,
    "I-C-AM-DIR": 85,
    "I-C-AM-DIS": 86,
    "I-C-AM-EXT": 87,
    "I-C-AM-LOC": 88,
    "I-C-AM-MNR": 89,
    "I-C-AM-PNC": 90,
    "I-C-AM-TMP": 91,
    "I-C-V": 92,
    "I-R-A0": 93,
    "I-R-A1": 94,
    "I-R-A2": 95,
    "I-R-A3": 96,
    "I-R-A4": 97,
    "I-R-AM-ADV": 98,
    "I-R-AM-DIR": 99,
    "I-R-AM-EXT": 100,
    "I-R-AM-LOC": 101,
    "I-R-AM-MNR": 102,
    "I-R-AM-PNC": 103,
    "I-R-AM-TMP": 104,
    "I-V": 105,
    "O": 106,
    "PAD_TOKEN": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "joint_fusion",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 107,
  "optimizer": {
    "freeze_steps": 0,
    "learning_rate": 2e-05,
    "lr_scheduler": "warmup_linear",
    "optim": "adam",
    "warmup_steps": 0,
    "weight_decay": 0.0
  },
  "output_attentions": false,
  "output_hidden_states": false,
  "pruned_heads": {},
  "syntax": {
    "adj_self_loop": true,
    "contextual_rnn": false,
    "emb_size": 768,
    "embed_position": true,
    "finetune_bert": true,
    "gelu_dropout": 0.1,
    "hidden_size": 768,
    "input_dropout": 0.5,
    "late_fusion_gate": "HighwayGateLayer",
    "late_fusion_gated_connection": true,
    "layer_dropout": 0.5,
    "layer_prepostprocess_dropout": 0.1,
    "mlp_layers": 1,
    "num_layers": 4,
    "pooling": "max",
    "post_layer_norm": false,
    "pre_layer_norm": true,
    "prune_k": -1,
    "rnn_dropout": 0.05,
    "rnn_hidden": 384,
    "rnn_layers": 1,
    "syntax_encoder": "GATEncoder",
    "tf_enc_act_at_skip_connection": false,
    "tf_enc_gate": "HighwayGateLayer",
    "tf_enc_gated_connection": false,
    "tf_enc_use_ffn": true,
    "use_dep_rel": false,
    "use_subj_obj": false
  },
  "torchscript": false,
  "type_vocab_size": 2,
  "use_syntax": true,
  "vocab_size": 28996
}
