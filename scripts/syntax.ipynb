{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../lib/syntax-augmented-bert')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from pprint import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = utils.processors['conll2005wsj_srl']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = processor.get_train_examples(data_dir='../lib/syntax-augmented-bert/checkpoints/1/conll2005_srl_udv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.utils.InputExample at 0x7fc65607ea50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = examples[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence_id', 'tokens', 'pos_tags', 'verb_indicator', 'dep_head', 'dep_label', 'tags', 'metadata'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../lib/syntax_augmented_bert/datasets/conll2005_srl_udv2/train.json'\n",
    "sample = json.loads(open(path, 'rt').readlines()[5])\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 [[0, 0, 0, 0, 0, 0, 0, 0, 0], ['The', 'new', 'rate', 'will', 'be', 'payable', 'Feb.', '15', '.']]\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "for i, line in enumerate(open(path, 'rt')):\n",
    "    sample = json.loads(line)\n",
    "    samples.append(sample)\n",
    "    if Counter(sample['verb_indicator'][0])[1] != 1:\n",
    "        print(i, sample['verb_indicator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0, 0, 0, 0, 0, 0, 0, 0], ['No', ',', 'it', 'was', \"n't\", 'Black', 'Monday', '.']]\n",
      "21 [[0, 0, 0, 0, 0, 0, 0], ['``', 'The', 'equity', 'market', 'was', 'illiquid', '.']]\n",
      "31 [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ['Then', 'in', 'a', 'lightning', 'plunge', ',', 'the', 'Dow', 'Jones', 'industrials', 'in', 'barely', 'an', 'hour', 'surrendered', 'about', 'a', 'third', 'of', 'their', 'gains', 'this', 'year', ',', 'chalking', 'up', 'a', '190.58-point', ',', 'or', '6.9', '%', ',', 'loss', 'on', 'the', 'day', 'in', 'gargantuan', 'trading', 'volume', '.']]\n",
      "56 [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ['At', 'this', 'point', ',', 'the', 'Dow', 'was', 'down', 'about', '35', 'points', '.']]\n",
      "95 [[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], ['``', 'It', 'screwed', 'things', 'up', ',', \"''\", 'said', 'one', 'major', 'specialist', '.']]\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "path = '../lib/syntax_augmented_bert/datasets/conll2005_srl_udv2/wsj-test.json'\n",
    "for i, line in enumerate(open(path, 'rt')):\n",
    "    sample = json.loads(line)\n",
    "    samples.append(sample)\n",
    "    if Counter(sample['verb_indicator'][0])[1] != 1:\n",
    "        print(i, sample['verb_indicator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2 = []\n",
    "path = '../data/synt/train.json'\n",
    "for i, line in enumerate(open(path, 'rt')):\n",
    "    sample = json.loads(line)\n",
    "    samples2.append(sample)\n",
    "    if Counter(sample['verb_indicator'][0])[1] != 1:\n",
    "        print(i, sample['verb_indicator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = samples[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rolls-Royce Motor Cars Inc. said it expects its U.S. sales to remain steady at about 1,200 cars in 1990 .'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(samples[5]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rolls-Royce', 'NNP', 0),\n",
       " ('Motor', 'NNP', 0),\n",
       " ('Cars', 'NNPS', 0),\n",
       " ('Inc.', 'NNP', 0),\n",
       " ('said', 'VBD', 0),\n",
       " ('it', 'PRP', 0),\n",
       " ('expects', 'VBZ', 0),\n",
       " ('its', 'PRP$', 0),\n",
       " ('U.S.', 'NNP', 0),\n",
       " ('sales', 'NNS', 0),\n",
       " ('to', 'TO', 0),\n",
       " ('remain', 'VB', 1),\n",
       " ('steady', 'JJ', 0),\n",
       " ('at', 'IN', 0),\n",
       " ('about', 'IN', 0),\n",
       " ('1,200', 'CD', 0),\n",
       " ('cars', 'NNS', 0),\n",
       " ('in', 'IN', 0),\n",
       " ('1990', 'CD', 0),\n",
       " ('.', '.', 0)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 7\n",
    "list(zip(samples[i]['tokens'], samples[i]['pos_tags'], samples[i]['verb_indicator'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rolls-Royce',\n",
       " 'Motor',\n",
       " 'Cars',\n",
       " 'Inc.',\n",
       " 'said',\n",
       " 'it',\n",
       " 'expects',\n",
       " 'its',\n",
       " 'U.S.',\n",
       " 'sales']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['tokens'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " ['Rolls-Royce',\n",
       "  'Motor',\n",
       "  'Cars',\n",
       "  'Inc.',\n",
       "  'said',\n",
       "  'it',\n",
       "  'expects',\n",
       "  'its',\n",
       "  'U.S.',\n",
       "  'sales',\n",
       "  'to',\n",
       "  'remain',\n",
       "  'steady',\n",
       "  'at',\n",
       "  'about',\n",
       "  '1,200',\n",
       "  'cars',\n",
       "  'in',\n",
       "  '1990',\n",
       "  '.']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['verb_indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Rolls-Royce', 4, 'compound'),\n",
       " (2, 'Motor', 4, 'compound'),\n",
       " (3, 'Cars', 4, 'compound'),\n",
       " (4, 'Inc.', 5, 'nsubj'),\n",
       " (5, 'said', 0, 'root'),\n",
       " (6, 'it', 7, 'nsubj'),\n",
       " (7, 'expects', 5, 'ccomp'),\n",
       " (8, 'its', 10, 'nmod:poss'),\n",
       " (9, 'U.S.', 10, 'compound'),\n",
       " (10, 'sales', 7, 'obj'),\n",
       " (11, 'to', 12, 'mark'),\n",
       " (12, 'remain', 7, 'xcomp'),\n",
       " (13, 'steady', 12, 'xcomp'),\n",
       " (14, 'at', 17, 'case'),\n",
       " (15, 'about', 16, 'advmod'),\n",
       " (16, '1,200', 17, 'nummod'),\n",
       " (17, 'cars', 12, 'obl'),\n",
       " (18, 'in', 19, 'case'),\n",
       " (19, '1990', 12, 'obl'),\n",
       " (20, '.', 5, 'punct')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 6\n",
    "sample = samples[i]\n",
    "list(zip(range(1, 1+len(sample['tokens'])), sample['tokens'], sample['dep_head'], sample['dep_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', 'Rolls-Royce'),\n",
       " ('O', 'Motor'),\n",
       " ('O', 'Cars'),\n",
       " ('O', 'Inc.'),\n",
       " ('O', 'said'),\n",
       " ('B-A0', 'it'),\n",
       " ('B-V', 'expects'),\n",
       " ('B-A1', 'its'),\n",
       " ('I-A1', 'U.S.'),\n",
       " ('I-A1', 'sales'),\n",
       " ('I-A1', 'to'),\n",
       " ('I-A1', 'remain'),\n",
       " ('I-A1', 'steady'),\n",
       " ('I-A1', 'at'),\n",
       " ('I-A1', 'about'),\n",
       " ('I-A1', '1,200'),\n",
       " ('I-A1', 'cars'),\n",
       " ('I-A1', 'in'),\n",
       " ('I-A1', '1990'),\n",
       " ('O', '.')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*sample['tags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['words', 'verb', 'verb_index', 'gold_tags'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['metadata'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rolls-Royce Motor Cars Inc. said it expects its U.S. sales to remain steady at about 1,200 cars in 1990 .'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = samples[6]\n",
    "' '.join(sample['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-A0',\n",
       " 'B-V',\n",
       " 'B-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'I-A1',\n",
       " 'O']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['metadata']['gold_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some `` circuit breakers '' installed after the October 1987 crash failed their first test , traders say , unable to cool the selling panic in both stocks and futures .\n",
      "Some\tDET\tDT\tdet\n",
      "``\tPUNCT\t``\tpunct\n",
      "circuit\tNOUN\tNN\tcompound\n",
      "breakers\tNOUN\tNNS\tnsubj\n",
      "''\tPUNCT\t''\tpunct\n",
      "installed\tVERB\tVBN\tacl\n",
      "after\tADP\tIN\tprep\n",
      "the\tDET\tDT\tdet\n",
      "October\tPROPN\tNNP\tnmod\n",
      "1987\tNUM\tCD\tnummod\n",
      "crash\tNOUN\tNN\tpobj\n",
      "failed\tVERB\tVBD\tccomp\n",
      "their\tPRON\tPRP$\tposs\n",
      "first\tADJ\tJJ\tamod\n",
      "test\tNOUN\tNN\tdobj\n",
      ",\tPUNCT\t,\tpunct\n",
      "traders\tNOUN\tNNS\tnsubj\n",
      "say\tVERB\tVBP\tROOT\n",
      ",\tPUNCT\t,\tpunct\n",
      "unable\tADJ\tJJ\tacomp\n",
      "to\tPART\tTO\taux\n",
      "cool\tVERB\tVB\txcomp\n",
      "the\tDET\tDT\tdet\n",
      "selling\tNOUN\tNN\tcompound\n",
      "panic\tNOUN\tNN\tdobj\n",
      "in\tADP\tIN\tprep\n",
      "both\tDET\tDT\tdet\n",
      "stocks\tNOUN\tNNS\tpobj\n",
      "and\tCCONJ\tCC\tcc\n",
      "futures\tNOUN\tNNS\tconj\n",
      ".\tPUNCT\t.\tpunct\n"
     ]
    }
   ],
   "source": [
    "sent = ' '.join(sample['tokens'])\n",
    "print(sent)\n",
    "doc = spacy.tokens.Doc(nlp.vocab, words=sample['tokens'])\n",
    "doc = nlp(doc)\n",
    "\n",
    "for token in doc:\n",
    "    # print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "    #         token.shape_, token.is_alpha, token.is_stop)\n",
    "    print('\\t'.join([\n",
    "        token.text, token.pos_, token.tag_, token.dep_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rolls-Royce, Motor, Cars]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "childs = list(doc[3].children)\n",
    "childs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4, 5, 0, 7, 5, 10, 10, 12, 12, 7, 12, 12, 16, 17, 14, 12, 18, 5]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntokens = len(doc)\n",
    "dep_head = [0 for _ in range(ntokens)]\n",
    "for token in doc:\n",
    "    for c in token.children:\n",
    "        assert dep_head[c.i] == 0\n",
    "        dep_head[c.i] = token.i + 1\n",
    "dep_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compound',\n",
       " 'compound',\n",
       " 'compound',\n",
       " 'nsubj',\n",
       " 'ROOT',\n",
       " 'nsubj',\n",
       " 'ccomp',\n",
       " 'poss',\n",
       " 'compound',\n",
       " 'nsubj',\n",
       " 'aux',\n",
       " 'ccomp',\n",
       " 'acomp',\n",
       " 'prep',\n",
       " 'quantmod',\n",
       " 'nummod',\n",
       " 'pobj',\n",
       " 'prep',\n",
       " 'pobj',\n",
       " 'punct']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_label = [token.dep_ for token in doc]\n",
    "dep_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 507/507 [00:00<00:00, 301kB/s]\n",
      "Downloading: 100%|██████████| 5.07M/5.07M [00:02<00:00, 1.70MB/s]\n",
      "Downloading: 100%|██████████| 150/150 [00:00<00:00, 65.9kB/s]\n",
      "Downloading: 100%|██████████| 25.0/25.0 [00:00<00:00, 11.4kB/s]\n",
      "Downloading: 100%|██████████| 2.24G/2.24G [02:02<00:00, 18.3MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"liaad/srl-en_xlmr-large\")\n",
    "model = AutoModel.from_pretrained(\"liaad/srl-en_xlmr-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer('I like what you want to do', return_tensors='pt')\n",
    "res = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "\n",
    "DEFAULT_SRLMODEL_PATH= \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\"\n",
    "\n",
    "def load_srl_predictor(path=DEFAULT_SRLMODEL_PATH):\n",
    "    from allennlp.predictors.predictor import Predictor\n",
    "    import allennlp_models.tagging\n",
    "    predictor = Predictor.from_path(path, cuda_device=0)\n",
    "    return predictor\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(path)\n",
    "    df['excerpt'] = df['excerpt'].str.lower()\n",
    "    df = df.loc[df['standard_error'] > 0]\n",
    "    return df\n",
    "\n",
    "srl_predictor = load_srl_predictor()\n",
    "df = load_data('../data/commonlitreadabilityprize/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, sent, score = next(zip(df['id'], df['excerpt'], df['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = srl_predictor.predict_batch_json([{'sentence': text} for text in df['excerpt'][:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = srl_predictor.predict(sentence=sent)\n",
    "tokens = res['words']\n",
    "ntokens = len(tokens)\n",
    "srlresults = res['verbs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = spacy.tokens.Doc(nlp.vocab, words=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "when the young people returned to the ballroom , it presented a decidedly changed appearance . instead of an interior scene , it was a winter landscape . the floor was covered with snow - white canvas , not laid on smoothly , but rumpled over bumps and hillocks , like a real snow field . the numerous palms and evergreens that had decorated the room , were powdered with flour and strewn with tufts of cotton , like snow . also diamond dust had been lightly sprinkled on them , and glittering crystal icicles hung from the branches . at each end of the room , on the wall , hung a beautiful bear - skin rug . these rugs were for prizes , one for the girls and one for the boys . and this was the game . the girls were gathered at one end of the room and the boys at the other , and one end was called the north pole , and the other the south pole . each player was given a small flag which they were to plant on reaching the pole . this would have been an easy matter , but each traveller was obliged to wear snowshoes . "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got spacy.tokens.doc.Doc)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/duxin/code/readability/scripts/syntax.ipynb Cell 36'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bathena2/home/duxin/code/readability/scripts/syntax.ipynb#ch0000059vscode-remote?line=0'>1</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39;49mmake_doc(doc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/allennlp/lib/python3.8/site-packages/spacy/language.py:1066\u001b[0m, in \u001b[0;36mLanguage.make_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.pyenv/versions/3.8.6/envs/allennlp/lib/python3.8/site-packages/spacy/language.py?line=1061'>1062</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length:\n\u001b[1;32m   <a href='file:///~/.pyenv/versions/3.8.6/envs/allennlp/lib/python3.8/site-packages/spacy/language.py?line=1062'>1063</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///~/.pyenv/versions/3.8.6/envs/allennlp/lib/python3.8/site-packages/spacy/language.py?line=1063'>1064</a>\u001b[0m         Errors\u001b[39m.\u001b[39mE088\u001b[39m.\u001b[39mformat(length\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(text), max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length)\n\u001b[1;32m   <a href='file:///~/.pyenv/versions/3.8.6/envs/allennlp/lib/python3.8/site-packages/spacy/language.py?line=1064'>1065</a>\u001b[0m     )\n\u001b[0;32m-> <a href='file:///~/.pyenv/versions/3.8.6/envs/allennlp/lib/python3.8/site-packages/spacy/language.py?line=1065'>1066</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(text)\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got spacy.tokens.doc.Doc)"
     ]
    }
   ],
   "source": [
    "doc = nlp.make_doc(doc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7375e5f9caff0daf1260c6443900e54dae4acd603bb2fa1b37170a1d390624c0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('pytorch-cu11-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
